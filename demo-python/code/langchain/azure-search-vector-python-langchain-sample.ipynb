{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search LangChain vector code sample\n",
    "This code demonstrates how to use Azure AI Search with OpenAI and Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r azure-search-vector-python-langchain-sample-requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load .env file (Copy .env-sample to .env and update accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "key_credential = os.environ[\"AZURE_SEARCH_ADMIN_KEY\"] if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else None\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]\n",
    "azure_openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "credential = key_credential or DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LangChain Azure OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Use API key if provided, otherwise use RBAC authentication\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LangChain Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=endpoint,\n",
    "    azure_search_key=key_credential,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    semantic_configuration_name=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "directory = os.path.join(\"..\", \"..\", \"data\", \"documents\")\n",
    "files = [\"Benefit_Options.pdf\", \"Northwind_Health_Plus_Benefits_Details.pdf\", \"Northwind_Standard_Benefits_Details.pdf\"]\n",
    "total_chunks = 0\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "for file in files:\n",
    "    loader = PyPDFLoader(os.path.join(directory, file))\n",
    "    file_chunks = loader.load_and_split(splitter)\n",
    "    results = vector_store.add_documents(documents=file_chunks)\n",
    "    total_chunks += len(results)\n",
    "    print(f\"Indexed {file}\")\n",
    "print(f\"Indexed {total_chunks} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    \"What is included in my Northwind Health Plus plan that is not in standard?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)  \n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Chunk Content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What is included in my Northwind Health Plus plan that is not in standard?\",\n",
    "    k=3, \n",
    "    search_type=\"hybrid\"\n",
    ")\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)  \n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Chunk Content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search with semantic reranking (powered by Bing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search with semantic reranking  \n",
    "docs_and_scores = vector_store.semantic_hybrid_search_with_score(  \n",
    "    query=\"What is included in my Northwind Health Plus plan that is not in standard?\",  \n",
    "    k=3,  \n",
    ")  \n",
    "  \n",
    "# Print the results  \n",
    "for doc, score in docs_and_scores:  \n",
    "    print(\"-\" * 80)  \n",
    "    answers = doc.metadata['answers']  \n",
    "    if answers:  \n",
    "        if answers.get('highlights'):  \n",
    "            print(f\"Semantic Answer: {answers['highlights']}\")  \n",
    "        else:  \n",
    "            print(f\"Semantic Answer: {answers['text']}\")  \n",
    "        print(f\"Semantic Answer Score: {score}\")  \n",
    "    print(\"Content:\", doc.page_content)  \n",
    "    captions = doc.metadata['captions']\n",
    "    print(f\"Score: {score}\") \n",
    "    if captions:  \n",
    "        if captions.get('highlights'):  \n",
    "            print(f\"Caption: {captions['highlights']}\")  \n",
    "        else:  \n",
    "            print(f\"Caption: {captions['text']}\")  \n",
    "    else:  \n",
    "        print(\"Caption not available\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
