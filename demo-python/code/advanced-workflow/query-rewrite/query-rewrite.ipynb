{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Rewriting (Azure AI Search)\n",
    "\n",
    "This code demonstrates how to use Azure AI Search with advanced query rewriting to improve the relevance of your search results. The code performs the following tasks:\n",
    "\n",
    "+ Create an index schema\n",
    "+ Load the sample data from a local folder\n",
    "+ Embed the documents in-memory using Azure OpenAI's text-embedding-ada-002 model\n",
    "+ Index the vector and nonvector fields on Azure AI Search\n",
    "+ Rewrite a sample question to improve the relevance of the result documents\n",
    "+ Manually combine the results of multiple rewritten queries using [Reciprocal Rank Fusion (RRF)](https://learn.microsoft.com/azure/search/hybrid-search-ranking).\n",
    "+ Use [simple query syntax](https://learn.microsoft.com/azure/search/query-simple-syntax) and [multi-vector queries](https://learn.microsoft.com/azure/search/vector-search-how-to-query?tabs=query-2023-11-01%2Cfilter-2023-11-01#multiple-vector-queries) to automatically combine multiple rewritten queries using built-in RRF\n",
    "\n",
    "The code uses Azure OpenAI to generate embeddings for title and content fields. You'll need access to Azure OpenAI to run this demo.\n",
    "\n",
    "The code reads the `text-sample.json` file, which contains the input data for which embeddings need to be generated.\n",
    "\n",
    "The output is a combination of human-readable text and embeddings that can be pushed into a search index.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access). You must have the Azure OpenAI service name and an API key.\n",
    "\n",
    "+ A deployment of the text-embedding-ada-002 embedding model.\n",
    "\n",
    "+ Azure AI Search, any tier, but choose a service that has sufficient capacity for your vector index. We recommend Basic or higher. [Enable semantic ranking](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run the hybrid query with semantic ranking.\n",
    "\n",
    "We used Python 3.11, [Visual Studio Code with the Python extension](https://code.visualstudio.com/docs/python/python-tutorial), and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) to test this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r query-rewrite-requirements.txt --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]\n",
    "azure_openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "azure_openai_chatgpt_deployment = os.environ[\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure AI Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import json\n",
    "\n",
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n",
    "\n",
    "output_path = os.path.join('..', '..', '..', 'output', 'docVectors.json')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    # Generate Document Embeddings using OpenAI Ada 002\n",
    "    # Read the text-sample.json\n",
    "    path = os.path.join('..', '..', '..', 'data', 'text-sample.json')\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        input_data = json.load(file)\n",
    "\n",
    "    titles = [item['title'] for item in input_data]\n",
    "    content = [item['content'] for item in input_data]\n",
    "    title_response = client.embeddings.create(input=titles, model=azure_openai_embedding_deployment)\n",
    "    title_embeddings = [item.embedding for item in title_response.data]\n",
    "    content_response = client.embeddings.create(input=content, model=azure_openai_embedding_deployment)\n",
    "    content_embeddings = [item.embedding for item in content_response.data]\n",
    "\n",
    "    # Generate embeddings for title and content fields\n",
    "    for i, item in enumerate(input_data):\n",
    "        title = item['title']\n",
    "        content = item['content']\n",
    "        item['titleVector'] = title_embeddings[i]\n",
    "        item['contentVector'] = content_embeddings[i]\n",
    "\n",
    "    # Output embeddings to docVectors.json file\n",
    "    output_directory = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(input_data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "\n",
    "Create your search index schema and vector search configuration. If you get an error, check the search service for available quota and check the .env file to make sure you're using a unique search index name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewriter created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters\n",
    ")\n",
    "\n",
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "            vectorizer=\"myVectorizer\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            name=\"myVectorizer\",\n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(\n",
    "                resource_uri=azure_openai_endpoint,\n",
    "                deployment_id=azure_openai_embedding_deployment,\n",
    "                api_key=azure_openai_key\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f'{result.name} created')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 108 documents\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Upload some documents to the index\n",
    "output_path = os.path.join('..', '..', '..', 'output', 'docVectors.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are indexing a very large number of documents, you can use the `SearchIndexingBufferedSender` which is an optimized way to automatically index the docs as it will handle the batching for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 108 documents in total\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "# Upload some documents to the index  \n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "  \n",
    "# Use SearchIndexingBufferedSender to upload the documents in batches optimized for indexing  \n",
    "with SearchIndexingBufferedSender(  \n",
    "    endpoint=endpoint,  \n",
    "    index_name=index_name,  \n",
    "    credential=credential,  \n",
    ") as batch_client:  \n",
    "    # Add upload actions for all documents  \n",
    "    batch_client.upload_documents(documents=documents)  \n",
    "print(f\"Uploaded {len(documents)} documents in total\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve chunks using hybrid search\n",
    "\n",
    "Before evaluating the effects of query rewriting, it's useful to establish a baseline as to what hybrid search returns without any query rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "import pandas as pd\n",
    "\n",
    "def hybrid_search(search_client: SearchClient, query: str) -> pd.DataFrame:\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[\n",
    "            # k_nearest_neighbors should be set to 50 in order to boost the relevance of hybrid search\n",
    "            # Increasing the vector recall set size from 1 to 50 in hybrid search benefits relevance by\n",
    "            # improving the diversity of vector query results that will be considered by RRF, ensuring a more comprehensive representation\n",
    "            # of the data results and more robustness to varying similarity scores or closely related similarity scores.\n",
    "            VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"contentVector\")\n",
    "        ],\n",
    "        top=3,\n",
    "        select=\"id, title, content\",\n",
    "        search_fields=[\"content\"]\n",
    "    )\n",
    "    data = [[result[\"id\"], result[\"title\"], result[\"content\"], result[\"@search.score\"]] for result in results]\n",
    "    return pd.DataFrame(data, columns=[\"id\", \"title\", \"content\", \"@search.score\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates the results of hybrid search using a sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>@search.score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Azure Storage</td>\n",
       "      <td>Azure Storage is a scalable, durable, and high...</td>\n",
       "      <td>0.033060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>Azure Data Lake Storage</td>\n",
       "      <td>Azure Data Lake Storage is a scalable, secure,...</td>\n",
       "      <td>0.032266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Azure Table Storage</td>\n",
       "      <td>Azure Table Storage is a fully managed, NoSQL ...</td>\n",
       "      <td>0.031754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    title  \\\n",
       "0   4            Azure Storage   \n",
       "1  36  Azure Data Lake Storage   \n",
       "2  52      Azure Table Storage   \n",
       "\n",
       "                                             content  @search.score  \n",
       "0  Azure Storage is a scalable, durable, and high...       0.033060  \n",
       "1  Azure Data Lake Storage is a scalable, secure,...       0.032266  \n",
       "2  Azure Table Storage is a fully managed, NoSQL ...       0.031754  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search(search_client, \"scalable storage solution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewriting queries for improved relevance of results\n",
    "\n",
    "Users often use terse terms such as \"scalable storage solution\". These terms may match the contents of documents in the search index, but often an LLM can rewrite the query to improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "REWRITE_PROMPT = \"\"\"You are a helpful assistant. You help users search for the answers to their questions.\n",
    "You have access to Azure AI Search index with 100's of documents. Rewrite the following question into 3 useful search queries to find the most relevant documents.\n",
    "Always output a JSON object in the following format:\n",
    "===\n",
    "Input: \"scalable storage solution\"\n",
    "Output: { \"queries\": [\"what is a scalable storage solution in Azure\", \"how to create a scalable storage solution\", \"steps to create a scalable storage solution\"] }\n",
    "===\n",
    "\"\"\"\n",
    "\n",
    "# If you are not using a supported model or region, you may not be able to use json_object response format\n",
    "# Please see https://learn.microsoft.com/azure/ai-services/openai/how-to/json-mode\n",
    "def rewrite_query(openai_client: AzureOpenAI, query: str):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=azure_openai_chatgpt_deployment,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": REWRITE_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Input: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON decoding error:\", e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates how an LLM can rewrite queries to improve their clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['what is Azure Search',\n",
       "  'features of Azure Search',\n",
       "  'how to set up Azure Search']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_query(client, \"what is azure sarch?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the rewritten queries manually using RRF\n",
    "\n",
    "Now that we can use a LLM to rewrite the query, we need to issue our queries and combine the results. We'll start by doing this manually to demonstrate how the RRF calculation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewrite_manual_rrf(search_client: SearchClient, openai_client: AzureOpenAI, query: str) -> pd.DataFrame:\n",
    "    rewritten_queries = rewrite_query(openai_client, query)\n",
    "    # pd.concat preserves the original index by default when concatenating tables\n",
    "    # This is important for the RRF calculation below\n",
    "    results = pd.concat([hybrid_search(search_client, rewritten_query) for rewritten_query in rewritten_queries[\"queries\"]], axis=0)\n",
    "    def rrf_score(row: pd.Series) -> float:\n",
    "        score = 0.0\n",
    "        k = 60\n",
    "        # rank = the original position in the results list the document was located at\n",
    "        for rank, df_row in results.iterrows():\n",
    "            # The RRF score is the sum of 1.0 / (k + document rank) in every result set the document shows up in\n",
    "            if df_row[\"id\"] == row[\"id\"]:\n",
    "                score += 1.0 / (k + rank)\n",
    "        return score\n",
    "    # Apply the RRF scoring function to every row in the data frame\n",
    "    results[\"rrf_score\"] = results.apply(rrf_score, axis=1)\n",
    "    # Return the deduplicated result set sorted by the most relevant RRF score\n",
    "    return rewritten_queries, results.drop_duplicates(subset=[\"id\"]).sort_values(by=\"rrf_score\", ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates how an unclear query (\"srch service\") is automatically rewritten and made more clear by an LLM. The resulting RRF score is higher for the most relevant document compared to the original search score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>@search.score</th>\n",
       "      <th>rrf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Azure Cognitive Search</td>\n",
       "      <td>Azure Cognitive Search is a fully managed sear...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services is a collection of AI...</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.048916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services are a set of AI servi...</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.048652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     title  \\\n",
       "0  40    Azure Cognitive Search   \n",
       "2  90  Azure Cognitive Services   \n",
       "1   3  Azure Cognitive Services   \n",
       "\n",
       "                                             content  @search.score  rrf_score  \n",
       "0  Azure Cognitive Search is a fully managed sear...       0.033333   0.050000  \n",
       "2  Azure Cognitive Services is a collection of AI...       0.032522   0.048916  \n",
       "1  Azure Cognitive Services are a set of AI servi...       0.032522   0.048652  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queries': ['What is Azure Cognitive Search service?', 'How to create an Azure Cognitive Search service?', 'Best practices for using Azure Cognitive Search service']}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "rewritten_queries, results = query_rewrite_manual_rrf(search_client, client, \"srch service\")\n",
    "display(results)\n",
    "print(rewritten_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the rewritten queries automatically using RRF\n",
    "\n",
    "We can use the built-in RRF instead of manually performing the RRF calculation ourselves. We will use query combination using boolean operators and multi-vector search to accomplish a similar goal. Please note that the RRF score will not be exactly the same as the manual calculation because the text index can be more efficiently queried using this approach and less-relevant documents are automatically filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewrite_automatic_rrf(search_client: SearchClient, openai_client: AzureOpenAI, query: str) -> pd.DataFrame:\n",
    "    rewritten_queries = rewrite_query(openai_client, query)\n",
    "    # Quote the rewritten queries before joining them in the query syntax\n",
    "    formatted_queries = [f'\"{rewritten_query}\"' for rewritten_query in rewritten_queries]\n",
    "    # Use the OR operator to join rewritten queries together\n",
    "    # https://learn.microsoft.com/azure/search/query-lucene-syntax#bkmk_boolean\n",
    "    search_text = \" | \".join(formatted_queries)\n",
    "    results = search_client.search(\n",
    "        search_text=search_text,\n",
    "        # Issue a vector query for every single rewritten query\n",
    "        vector_queries=[VectorizableTextQuery(text=rewritten_query, k_nearest_neighbors=50, fields=\"contentVector\") for rewritten_query in rewritten_queries],\n",
    "        query_type=\"simple\",\n",
    "        # Any rewritten query from the joined query could match\n",
    "        search_mode=\"any\",\n",
    "        search_fields=[\"content\"],\n",
    "        top=3\n",
    "    )\n",
    "    # @search.score is equivalent to the manually computed RRF score above\n",
    "    data = [[result[\"id\"], result[\"title\"], result[\"content\"], result[\"@search.score\"]] for result in results]\n",
    "    return rewritten_queries, pd.DataFrame(data, columns=[\"id\", \"title\", \"content\", \"@search.score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates how the automatic approach has similar results to the manual one, even though the scores are not exactly equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>@search.score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Azure Cognitive Search</td>\n",
       "      <td>Azure Cognitive Search is a fully managed sear...</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services are a set of AI servi...</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Azure Data Explorer</td>\n",
       "      <td>Azure Data Explorer is a fast, fully managed d...</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     title  \\\n",
       "0  40    Azure Cognitive Search   \n",
       "1   3  Azure Cognitive Services   \n",
       "2  34       Azure Data Explorer   \n",
       "\n",
       "                                             content  @search.score  \n",
       "0  Azure Cognitive Search is a fully managed sear...       0.016667  \n",
       "1  Azure Cognitive Services are a set of AI servi...       0.016393  \n",
       "2  Azure Data Explorer is a fast, fully managed d...       0.016129  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queries': ['Azure search service', 'how to create an Azure search service', 'best practices for Azure search service']}\n"
     ]
    }
   ],
   "source": [
    "rewritten_queries, results = query_rewrite_automatic_rrf(search_client, client, \"srch service\")\n",
    "display(results)\n",
    "print(rewritten_queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to improve relevance using hybrid and semantic\n",
    "\n",
    "Once you are using the automatic RRF combination method, you can add semantic ranking to improve relevance further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewrite_automatic_rrf_semantic(search_client: SearchClient, openai_client: AzureOpenAI, query: str) -> pd.DataFrame:\n",
    "    rewritten_queries = rewrite_query(openai_client, query)\n",
    "    # Quote the rewritten queries before joining them together using the query syntax\n",
    "    formatted_queries = [f'\"{rewritten_query}\"' for rewritten_query in rewritten_queries]\n",
    "    # Use the OR operator to join rewritten queries together\n",
    "    # https://learn.microsoft.com/azure/search/query-lucene-syntax#bkmk_boolean\n",
    "    search_text = \" | \".join(formatted_queries)\n",
    "    # The semantic ranker expects plain text queries with no search operators\n",
    "    semantic_query = \" \".join(rewritten_queries[\"queries\"])\n",
    "    results = search_client.search(\n",
    "        search_text=search_text,\n",
    "        # Issue a vector query for every single rewritten query\n",
    "        vector_queries=[VectorizableTextQuery(text=rewritten_query, k_nearest_neighbors=50, fields=\"contentVector\") for rewritten_query in rewritten_queries],\n",
    "        # Any rewritten query from the joined query could match\n",
    "        search_mode=\"any\",\n",
    "        search_fields=[\"content\"],\n",
    "        query_type=\"simple\",\n",
    "        # Pass in the plain text concatenation of the rewritten queries for semantic ranking\n",
    "        semantic_query=semantic_query,\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        top=3\n",
    "    )\n",
    "    # @search.score is equivalent to the manually computed RRF score above\n",
    "    # @search.rerankerscore is the semantic reranking of the combined results\n",
    "    data = [[result[\"id\"], result[\"title\"], result[\"content\"], result[\"@search.score\"], result[\"@search.reranker_score\"]] for result in results]\n",
    "    return rewritten_queries, pd.DataFrame(data, columns=[\"id\", \"title\", \"content\", \"@search.score\", \"@search.reranker_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates how the semantic score compares to the RRF score. The semantic score ranges from 0-4, where a higher score indicates higher relvance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>@search.score</th>\n",
       "      <th>@search.reranker_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Azure Cognitive Search</td>\n",
       "      <td>Azure Cognitive Search is a fully managed sear...</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>3.679841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services are a set of AI servi...</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>2.989737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services is a collection of AI...</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>2.972886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     title  \\\n",
       "0  40    Azure Cognitive Search   \n",
       "1   3  Azure Cognitive Services   \n",
       "2  90  Azure Cognitive Services   \n",
       "\n",
       "                                             content  @search.score  \\\n",
       "0  Azure Cognitive Search is a fully managed sear...       0.016667   \n",
       "1  Azure Cognitive Services are a set of AI servi...       0.016393   \n",
       "2  Azure Cognitive Services is a collection of AI...       0.015152   \n",
       "\n",
       "   @search.reranker_score  \n",
       "0                3.679841  \n",
       "1                2.989737  \n",
       "2                2.972886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queries': ['what is Azure Cognitive Search service', 'how to create an Azure Cognitive Search service', 'best practices for managing Azure Cognitive Search service']}\n"
     ]
    }
   ],
   "source": [
    "rewritten_queries, results = query_rewrite_automatic_rrf_semantic(search_client, client, \"srch service\")\n",
    "display(results)\n",
    "print(rewritten_queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
